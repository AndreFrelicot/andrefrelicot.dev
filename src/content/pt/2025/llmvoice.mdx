---  
title: LLMVoice 1.0  
date: 2025-10-14  
description: Demonstração técnica que permite avaliar as novas APIs de reconhecimento de voz do iOS 26 (SpeechAnalyzer / SpeechTranscriber) e a execução de modelos LLM de código aberto (quantizados em 4 bits) localmente em um iPhone compatível com o framework MLX.  
tags: [apps, llm, mlx, apple_intelligence, ios26, speechanalyzer, speechtranscriber, audio, voice, local, on_device, source_code]  
image: /images/2025/llmvoice.webp  
---  

<ThemeImage lightSrc="/images/2025/llmvoice.webp" darkSrc="/images/2025/llmvoice.webp" alt="LLMVoice em ação" width={800} height={600} priority={true} />  

<br/>  

Aqui está o **LLMVoice**, uma demonstração técnica que permite avaliar as novas APIs de reconhecimento de voz do iOS 26 (**SpeechAnalyzer / SpeechTranscriber**) e a execução de modelos **LLM de código aberto** (quantizados em **4 bits**) localmente em um iPhone compatível com o framework **MLX**.  

Você pode resumir uma transcrição ou enviar um prompt diretamente para o modelo.  
Vamos ser honestos — modelos tão compactados não são realmente úteis, mas é divertido vê-los “alucinar”.  
Ainda assim, há potência suficiente para colocar meu velho iPhone 13 de joelhos!  

Aqui estão os modelos disponíveis para download:  
<br/>  

**Gemma3_1b** (mlx-community/gemma-3-1b-it-4bit)  
<br/>  
**Qwen25_05b** (lmstudio-community/Qwen2.5-0.5B-Instruct-MLX-4bit)  
<br/>  
**Llama32_1b** (mlx-community/Llama-3.2-1B-Instruct-4bit)  
<br/>  

## Código-fonte  
[LLMVoice source code](https://github.com/AndreFrelicot/llmvoice)  

## Requisitos do sistema  

**iOS 26.0+ / iPadOS 26.0+**  

### Para Apple Intelligence  
- iPhone 15 Pro ou modelo posterior  
- Apple Intelligence ativada nas configurações  

### Para modelos locais MLX  
- iPhone 12 ou modelo posterior (chip A14 Bionic ou superior)  
- iPad Pro 2021 ou modelo posterior (chip M1 ou superior)  
- iPad Air 5ª geração ou modelo posterior (chip M1 ou superior)  
<br/>  
GPU Metal com recursos específicos: **air.simd_sum**, suporte ao kernel **rmsfloat16**.  

### Armazenamento  
- Tamanho do app: aproximadamente **50 MB**  
- Downloads de modelos (somente MLX):  
  - **Qwen2.5 (0,5B)**: aproximadamente **150 MB**  
  - **Gemma 3 (1B)**: aproximadamente **300 MB**  
  - **Llama 3.2 (1B)**: aproximadamente **500 MB**  
<br/>  
